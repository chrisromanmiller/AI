{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christophermiller/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'TicTacToe' from '/Users/christophermiller/Documents/GitHub/ai/TicTacToe/venv/TicTacToe.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import gym.spaces\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow                as tf\n",
    "import tensorflow.contrib.layers as layers\n",
    "from collections import namedtuple\n",
    "import TicTacToe\n",
    "from collections import Counter\n",
    "import Players\n",
    "from importlib import reload\n",
    "reload(Players)\n",
    "reload(TicTacToe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "def TicTacToe_model(placeholder, scope, num_actions = 9):\n",
    "    '''A model for a TicTacToe Q-function\n",
    "    Inputs:\n",
    "        placeholder: [None, ob_dim] placeholder representing inputs to our neural network\n",
    "        scope: a string that becomes the scope of all layers in this network\n",
    "        reuse: \n",
    "        num_actions: an int representing the number of possible actions (the output dimension)\n",
    "    \n",
    "    The final layer outputs values in the range [-1,1], which matches the range of possible target q-values\n",
    "    placeholder = tf.contrib.layers.flatten(placeholder)\n",
    "    \n",
    "    The Q-function is thought of as a function of two varables Q(s,a). Here we treat it as a num_actions-dimensional\n",
    "    function of one variable, so that Q(s,a) = Q(s)[a]\n",
    "    \n",
    "    We initialize bias and weights to zero, except for the final layer, where the weights are initialized to one.  \n",
    "    \n",
    "    Returns:\n",
    "        model: [None, num_actions] variable representing the outputs of our q-function\n",
    "    '''\n",
    "    with tf.variable_scope(scope):\n",
    "        out = placeholder\n",
    "        out = tf.cast(out, tf.float32)\n",
    "        out = tf.layers.dense(out, 64  , bias_initializer = tf.zeros_initializer(), activation = tf.nn.softmax)\n",
    "        out = tf.layers.dense(out, 64  , bias_initializer = tf.zeros_initializer(), activation = tf.nn.softmax)\n",
    "        out = tf.layers.dense(out, 64  , bias_initializer = tf.zeros_initializer(), activation = tf.nn.softmax)\n",
    "        out = tf.layers.dense(out, num_actions , kernel_initializer = tf.zeros_initializer(), bias_initializer = tf.zeros_initializer(), activation = tf.nn.sigmoid)\n",
    "        out = (out*2)-1\n",
    "    return out\n",
    "\n",
    "    \n",
    "def sample_action(model, mask_placeholder):\n",
    "    '''Symbolically selects an action from logits with restrictions\n",
    "    Inputs: \n",
    "        model: a [None, action_dim] variable consisting of logits\n",
    "        mask_placeholder: a [None, action_dim] placeholder that will be fed boolean vectors\n",
    "    \n",
    "    Returns:\n",
    "        A random legal action, where legal values are those which mask_placeholder assigns 1\n",
    "        The probabilities are weighted according to the logits\n",
    "    '''\n",
    "    out = model\n",
    "    dist = tf.distributions.Categorical(probs=maskedSoftmax(out, mask_placeholder))\n",
    "    return dist.sample()\n",
    "    \n",
    "    \n",
    "def maskedSoftmax(logits, mask):\n",
    "    '''Computes the softmax of our logits, given that some moves are illegal\n",
    "    Inputs:\n",
    "        Masked softmax over dim 1\n",
    "        param logits: [None, ac_dim]\n",
    "        param mask: [None, ac_dim]\n",
    "        \n",
    "        ***This code is edited from code we found online***\n",
    "        We do not want there to be any probability of making illegal moves. \n",
    "        Intuitively, we are computing softmax of our logits, but pretending that the only entries \n",
    "            are the legal ones.\n",
    "        This is actually implemented via SparseTensor calculations.\n",
    "        \n",
    "    Returns: \n",
    "        result: [None, ac_dim] a sequence of probability distributions, with zero probability of illegal moves\n",
    "    '''\n",
    "    indices = tf.where(mask)\n",
    "    values = tf.gather_nd(logits, indices)\n",
    "    denseShape = tf.cast(tf.shape(logits), tf.int64)\n",
    "    \n",
    "    # Tensorflow will automatically set output probabilities to zero of \n",
    "    # undesignated entries in sparse vector\n",
    "    sparseResult = tf.sparse_softmax(tf.SparseTensor(indices, values, denseShape))\n",
    "    \n",
    "    result = tf.scatter_nd(sparseResult.indices, sparseResult.values, sparseResult.dense_shape)\n",
    "    result.set_shape(logits.shape)\n",
    "    return result\n",
    "\n",
    "\n",
    "def batch_rollout(player,opponent, env, max_time_steps = 100):\n",
    "    '''Produces a batch of rollouts from the environment.\n",
    "    Inputs:\n",
    "        player: realization of Player.Player abstract class\n",
    "        opponent: realization of Player.Player abstract class\n",
    "        env: an environment\n",
    "        max_time_steps: an integer\n",
    "    \n",
    "    This function plays a number of rounds of a two-player game, and returns the trajectories observed by player\n",
    "    \n",
    "    Returns:\n",
    "        paths: a list of dictionaries. Each dictionary is a rollout, and takes the keys:\n",
    "            'observation': [None, obs_dime] np.array of the observations of player\n",
    "            'action': [None,] np.array of the actions of player\n",
    "            'reward': [None,] np.array of the rewards gotten by player\n",
    "        batch_winners: TODO\n",
    "    '''\n",
    "    paths = []\n",
    "    batch_winners = Counter({0: 0, 1: 0, 2:0})\n",
    "    time_steps = 0\n",
    "    while time_steps < max_time_steps:\n",
    "        path = sample_trajectory(player,opponent,env)\n",
    "        paths += [path]\n",
    "        batch_winners[env.current_winner] +=1\n",
    "        time_steps += len(path['observation'])\n",
    "    return paths, batch_winners\n",
    "    \n",
    "    \n",
    "    \n",
    "def sample_trajectory(player, opponent, env):\n",
    "    \"\"\"Produces a single rollout of the environment following the player policy\n",
    "    Inputs:\n",
    "        player:   realization of Player.Player abstract class\n",
    "        opponent: realization of Player.Player abstract class\n",
    "        env:      environment which follows open ai gym environment structure and has a current_player int either 1 or 2\n",
    "        TODO: it doesn't quite match the reward structure, no?^\n",
    "       \n",
    "    Returns:\n",
    "    a list of dictionaries. Each dictionary is a rollout, and takes the keys:\n",
    "        'observation': [None, obs_dime] np.array of the observations of player\n",
    "        'action': [None,] np.array of the actions of player\n",
    "        'reward': [None,] np.array of the rewards gotten by player\n",
    "    \"\"\"\n",
    "    \n",
    "    obs, acs, rewards, masks = [], [], [], []\n",
    "    ob = env.reset()\n",
    "    done = False\n",
    "    player_has_acted = False\n",
    "    action = None\n",
    "    \n",
    "    #Do rest of moves\n",
    "    while not done:\n",
    "        #Get current observation of current player\n",
    "        ob = env.get_observation(env.current_player)\n",
    "        legal_moves = env.legal_moves()\n",
    "        if env.current_player == 1:\n",
    "            #Reward is recorded as results of state,action pair... need to check player 1 has acted already\n",
    "            if player_has_acted:\n",
    "                rewards.append(env.get_reward(1))\n",
    "            else:\n",
    "                player_has_acted = True\n",
    "                \n",
    "            action = player.policy(np.array([ob]), np.array([legal_moves]))\n",
    "            obs.append(ob)\n",
    "            acs.append(action[0])\n",
    "            masks.append(legal_moves)\n",
    "        else:\n",
    "            action = opponent.policy(np.array([ob]), np.array([legal_moves]))\n",
    "        done, _ = env.step(action[0]) \n",
    "\n",
    "    #Need to record final reward for player 1\n",
    "    rewards.append(env.get_reward(1))\n",
    "    \n",
    "    path = {\"observation\" : np.array(obs, dtype=np.int32), \n",
    "                \"reward\" : np.array(rewards, dtype=np.float32), \n",
    "                \"action\" : np.array(acs, dtype=np.int32),\n",
    "                \"mask\" : np.array(masks, dtype=np.int32)}\n",
    "    return path\n",
    "\n",
    "    \n",
    "    \n",
    "def sum_of_rewards(paths, gamma = .6): \n",
    "    re_n = [path[\"reward\"] for path in paths]\n",
    "    q_n = []\n",
    "    for seq_of_rewards in re_n:\n",
    "        for t in range(len(seq_of_rewards)):\n",
    "            weighted_sequence = seq_of_rewards[t:] * np.array([gamma**i for i in range(len(seq_of_rewards[t:]))])\n",
    "            q_n.append(np.sum(weighted_sequence))\n",
    "    adv_n = q_n\n",
    "    return adv_n\n",
    "        \n",
    "def standardize_advantage(adv_n):\n",
    "    adv_n = (adv_n - np.mean(adv_n)) \n",
    "    adv_n = adv_n * (1.0/(np.std(adv_n)+.0000001))\n",
    "    return adv_n\n",
    "\n",
    "def get_log_prob(model, action_placeholder, mask_placeholder):\n",
    "    action_dim = 9 \n",
    "    logits = model\n",
    "    \n",
    "    indices = tf.where(mask_placeholder)\n",
    "    values = tf.gather_nd(logits, indices)\n",
    "    denseShape = tf.cast(tf.shape(logits), tf.int64)\n",
    "    \n",
    "    \"\"\"THIS IS THE KEY: tensorflow will automatically set output probabilities to zero of undesignated entries in sparse vector\"\"\"\n",
    "    sparseResult = tf.sparse_softmax(tf.SparseTensor(indices, values, denseShape))\n",
    "    \n",
    "    probability_dist = tf.scatter_nd(sparseResult.indices, sparseResult.values, sparseResult.dense_shape)\n",
    "#     probability_dist = probability_dist.set_shape(logits.shape)\n",
    "    log_probability_dist = tf.scatter_nd(sparseResult.indices, tf.log(sparseResult.values), sparseResult.dense_shape)\n",
    "\n",
    "    \"\"\"Want to emulate this:\"\"\"\n",
    "#     probability_dist = tf.nn.softmax(logits)\n",
    "#     legal_pseudo_probability_dist = probability_dist*values\n",
    "#     legalprobability_dist = tf.divide(legal_pseudo_probability_dist, tf.reduce_sum(legal_pseudo_probability_dist, axis= 1))\n",
    "    \n",
    "    prod = tf.multiply(probability_dist, tf.one_hot(action_placeholder, action_dim ))\n",
    "    \n",
    "    entropy = - tf.reduce_sum(probability_dist * log_probability_dist, axis = 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    log_prob = tf.log(tf.reduce_sum(prod , axis = 1 ))\n",
    "#    log_prob = -tf.nn.sparse_softmax_cross_entropy_with_logits(labels= action_placeholder, logits= tf.SparseTensor(indices, values, denseShape))\n",
    "    return log_prob, entropy\n",
    "\n",
    "def loss_and_update_op(log_prob, entropy, adv_n, entropy_coeff = .1):\n",
    "    loss = -tf.reduce_mean(log_prob * adv_n) -  entropy_coeff * entropy\n",
    "    optimizer = tf.train.AdamOptimizer(5e-3)\n",
    "    update_op = optimizer.minimize(loss)\n",
    "    return loss, update_op, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TicTacToe_model() got multiple values for argument 'scope'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-163328d27d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"policy_gradient\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;31m#old_model = TicTacToe_model(board_placeholder, 9, scope = \"model-2\", reuse=tf.AUTO_REUSE)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel_input_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: TicTacToe_model() got multiple values for argument 'scope'"
     ]
    }
   ],
   "source": [
    "#Main code for running policy gradient\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#define the board, models *symbolically*\n",
    "observation_placeholder = tf.placeholder(shape = [None, 3,3], dtype = tf.int32)\n",
    "adv_n_placeholder = tf.placeholder(shape = [None], dtype = tf.float32)\n",
    "action_placeholder = tf.placeholder(shape = [None], dtype = tf.int32)\n",
    "mask_placeholder = tf.placeholder(shape=[None, 9], dtype = tf.int32)\n",
    "\n",
    "\n",
    "model = TicTacToe_model(observation_placeholder, 9, scope = \"policy_gradient\")\n",
    "#old_model = TicTacToe_model(board_placeholder, 9, scope = \"model-2\")\n",
    "model_input_s = sample_action(model, mask_placeholder)\n",
    "\n",
    "#Define Loss functions *symbolically*\n",
    "log_prob, entropy = get_log_prob(model, action_placeholder, mask_placeholder)\n",
    "loss, update_op, optimizer = loss_and_update_op(log_prob, entropy, adv_n_placeholder, entropy_coeff = 0)\n",
    "\n",
    "#start a session\n",
    "sess =tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#Defines player, opponent\n",
    "player = Players.NN_Player(model, model_input_s, sess, observation_placeholder, mask_placeholder, duplicate=False, deterministic = False)\n",
    "opponent = Players.Random_Player()\n",
    "\n",
    "#Loads old player,opponent\n",
    "# temp_file_name = './bot_10_28_v6.ckpt'\n",
    "\n",
    "#Want to duplicate session\n",
    "# saver = tf.train.Saver()\n",
    "# saver.restore(sess, temp_file_name)\n",
    "\n",
    "\n",
    "# opponent = Players.NN_Player(model, model_input_s, sess, observation_placeholder, mask_placeholder)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#start an environment\n",
    "env = TicTacToe.TicTacToe()\n",
    "\n",
    "number_updates_per_expert_update = 5\n",
    "number_expert_updates = 1000\n",
    "\n",
    "for k in range(number_expert_updates):\n",
    "    print(\"iteration number\", k)\n",
    "    \n",
    "    batch_adv_n = []\n",
    "    iteration_winners = Counter({0:0,1:0,2:0})\n",
    "    \n",
    "    tic = time.time()\n",
    "    for i in range(number_updates_per_expert_update):\n",
    "        paths, batch_winners = batch_rollout(player, opponent, env, max_time_steps=1000)\n",
    "        iteration_winners += batch_winners\n",
    "        \n",
    "        adv_n = sum_of_rewards(paths)\n",
    "        batch_adv_n = batch_adv_n + adv_n\n",
    "        \n",
    "\n",
    "        boards = np.concatenate([path['observation'] for path in paths])\n",
    "        masks = np.concatenate([path['mask'] for path in paths])\n",
    "        actions = np.squeeze(np.concatenate([path[\"action\"] for path in paths])).astype(int)\n",
    "        \n",
    "        sess.run(update_op, feed_dict = {mask_placeholder: masks, adv_n_placeholder: adv_n, observation_placeholder: boards , action_placeholder: actions})\n",
    "    \n",
    "    \n",
    "    #Unwind win data:\n",
    "#     print(iteration_winners)\n",
    "    print(\"mean adv\", np.mean(batch_adv_n))\n",
    "    print(\"iteration time\", time.time() - tic)\n",
    "#     print(paths[0])\n",
    "    \n",
    "    \n",
    "    expert_player = Players.Expert_Player()\n",
    "    _, expert_batch_winners = batch_rollout(player, expert_player, env, max_time_steps=900)\n",
    "    player_loss_percentage_vs_expert = expert_batch_winners[2]*1.0/(expert_batch_winners[0] + expert_batch_winners[1] + expert_batch_winners[2])\n",
    "    print(\"loss percent vs expert\", player_loss_percentage_vs_expert)\n",
    "    opponent = Players.NN_Player(model, model_input_s, sess, observation_placeholder, mask_placeholder)\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./bot_11_01_q_v2.ckpt'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save current net\n",
    "\n",
    "temp_file_name = './bot_11_01_q_v2.ckpt'\n",
    "\n",
    "#Want to duplicate session\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, temp_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./bot_11_01_q_v2.ckpt\n"
     ]
    }
   ],
   "source": [
    "#Load current net\n",
    "\n",
    "temp_file_name = './bot_11_01_q_v2.ckpt'\n",
    "\n",
    "#Want to duplicate session\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, temp_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Say something: 0\n",
      "[0]\n",
      "1\n",
      "[[ 1  0  0]\n",
      " [ 0 -1  0]\n",
      " [ 0  0  0]]\n",
      "Say something: 8\n",
      "[8]\n",
      "1\n",
      "[[ 1  0  0]\n",
      " [ 0 -1 -1]\n",
      " [ 0  0  1]]\n",
      "Say something: 3\n",
      "[3]\n",
      "1\n",
      "[[ 1  0  0]\n",
      " [ 1 -1 -1]\n",
      " [-1  0  1]]\n",
      "Say something: 2\n",
      "[2]\n",
      "1\n",
      "[[ 1  0  1]\n",
      " [ 1 -1 -1]\n",
      " [-1 -1  1]]\n",
      "Say something: 1\n",
      "[1]\n",
      "1\n",
      "[[ 0 -1  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "human = Players.Human_Player()\n",
    "player.epsilon = 0\n",
    "env = TicTacToe.TicTacToe()\n",
    "paths, batch_winners = batch_rollout(opponent,human,env,max_time_steps=10000)\n",
    "print(batch_winners)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(Players)\n",
    "\n",
    "\n",
    "def symbolic_Q_update(model, target_placeholder, action_placeholder, learning_rate = .01):\n",
    "    '''Produce the symbolic variables for loss, the update, and the optimizer\n",
    "    Inputs:\n",
    "        model: [None, action_dim] variable consisting of Q values\n",
    "        target_placeholder: [None,] placeholder that will be fed target values for the Q-function\n",
    "        action_placeholder: [None,] placeholder that will be fed the action values\n",
    "        learning_rate: float representing the size of gradient step\n",
    "        \n",
    "        The loss is the mean squared error ||Q(s,a) - Q'(s,a)||^2\n",
    "        We use AdamOptimizer with no bells or whistles\n",
    "        \n",
    "    Returns:\n",
    "        update_op: a method to be called when we desire to take a gradient step\n",
    "    '''\n",
    "    q_action_s = tf.reduce_sum(tf.multiply(model, tf.one_hot(action_placeholder, 9)), 1)\n",
    "    loss = tf.losses.mean_squared_error(q_action_s, target_placeholder)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "    update_op = optimizer.minimize(loss)\n",
    "    return update_op, loss\n",
    "\n",
    "def compute_target_values(model, next_state, masks, not_end_of_path, reward, decay = .99, verbose = False):\n",
    "    '''Computes the target values for our Q-function update\n",
    "    Inputs: \n",
    "        model: [None, action_dim] variable consisting of Q values\n",
    "        next_state: [None, ob_dim] np.array of states\n",
    "        masks: [None, ac_dim] np.array of masks (legal moves)\n",
    "        not_end_of_path: [None,] np.array of 0,1 integers (0 denotes the end of a rolllout)\n",
    "        reward: [None,] np.array of real numbers representing the return of the action resulting in next_state\n",
    "        decay: real number in [0,1] representing the decay rate (often called gamma)\n",
    "        verbose: Boolean\n",
    "    \n",
    "    This function is used to compute the Bellman backup values used to update our Q-function. \n",
    "        Recall: Q(s,a,s') <~~  r(s,a) +  max_a' [Q(s',a')]\n",
    "        The right side of this equation is called the target value.\n",
    "    \n",
    "    Returns:\n",
    "        target: [None,] batch of real numbers, indicating target values\n",
    "    ''' \n",
    "    next_state_Qs = sess.run(model, feed_dict= {observation_placeholder: next_state})\n",
    "    future_expected_reward = []\n",
    "    for next_state_Q, mask in zip(next_state_Qs,masks):\n",
    "        indices = np.where(mask)\n",
    "        values = next_state_Q[indices]\n",
    "        future_expected_reward.append(np.max(values))\n",
    "    future_reward_if_not_done = [eop * fer for eop, fer in zip(not_end_of_path.tolist(), future_expected_reward)]\n",
    "    target = reward + future_reward_if_not_done\n",
    "    if verbose:\n",
    "        print(\"not end of path\", not_end_of_path)\n",
    "        print(\"future expected reward\", future_expected_reward)\n",
    "        print(\"future reward if not done\", future_reward_if_not_done)\n",
    "        print(\"reward\", reward)\n",
    "        print(\"target\", target)\n",
    "        print(\"--\")\n",
    "    return target\n",
    "\n",
    "def sample_paths(paths, batch_size = 10):\n",
    "    '''From a collection of rollouts, this samples a random uniform batch\n",
    "    Inputs: \n",
    "        paths: a list of dictionaries containing the data of a rollout\n",
    "        batch_size: integer determining batch size to be returned\n",
    "    \n",
    "    Returns:\n",
    "        state1: [batch_size, ob_dim] np.array of states\n",
    "        action: [batch_size,] np.array of actions\n",
    "        state2: [batch_size, ob_dim] np.array of states\n",
    "        reward: [batch_size,] np.array of states\n",
    "        mask:   [batch_size,ac_dim] np.array of masks\n",
    "        done:   [batch_size,] binary np.array. \n",
    "            A 0 corresponds to a terminal game state, a 1 is a non-terminal game state\n",
    "    '''\n",
    "    \n",
    "    #Make the easy lists\n",
    "    observation_list = np.concatenate([path['observation'] for path in paths])\n",
    "    action_list = np.concatenate([path['action'] for path in paths])\n",
    "    reward_list = np.concatenate([path['reward'] for path in paths])\n",
    "    mask_list = np.concatenate([path['mask'] for path in paths])\n",
    "\n",
    "    #Make the done list\n",
    "    number_of_states = len(observation_list)\n",
    "    list_of_ones = [1] * number_of_states\n",
    "    partial_sum =0\n",
    "    for path in paths:\n",
    "        partial_sum += len(path['observation'])\n",
    "        list_of_ones[partial_sum-1] = 0\n",
    "    done_list = list_of_ones\n",
    "    \n",
    "\n",
    "    #Select randomly chosen entries\n",
    "    indices = np.random.choice(number_of_states, batch_size) \n",
    "    state1 = np.array([observation_list[i] for i in indices])\n",
    "    action = np.array([action_list[i] for i in indices])\n",
    "    state2 = np.array([observation_list[(i+1) % number_of_states] for i in indices])\n",
    "    reward = np.array([reward_list[i] for i in indices])\n",
    "    mask = np.array([mask_list[(i+1) % number_of_states] for i in indices])\n",
    "    done = np.array([done_list[i] for i in indices])\n",
    "    \n",
    "    return state1, action, state2 , reward, mask, done\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: not duplicating session, evaluation will change with tf updates\n",
      "Destroying NN_Player and Session...\n",
      "Destroying NN_Player and Session...\n",
      "[[0.7624899  0.62806654 0.72391427 0.2153095  0.78453815 0.29561567\n",
      "  0.717113   0.36618185 0.62203956]]\n",
      "Counter({2: 197, 0: 74, 1: 34})\n",
      "batch percentages [0.24262295081967214, 0.11147540983606558, 0.6459016393442623]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "[[0.8248923  0.7050432  0.7919456  0.44908166 0.8942462  0.42637086\n",
      "  0.7486932  0.59787965 0.7915474 ]]\n",
      "Counter({2: 202, 1: 46, 0: 43})\n",
      "batch percentages [0.14776632302405499, 0.15807560137457044, 0.6941580756013745]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.7777405  0.74678445 0.77774405 0.45682645 0.89168394 0.55582595\n",
      "  0.76682734 0.75960135 0.7733172 ]]\n",
      "Counter({2: 178, 0: 55, 1: 46})\n",
      "batch percentages [0.1971326164874552, 0.16487455197132617, 0.6379928315412187]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.20727515 0.63013434 0.53498113 0.23347938 0.7914158  0.29806864\n",
      "  0.90783226 0.7110995  0.84748554]]\n",
      "Counter({0: 105, 2: 98, 1: 62})\n",
      "batch percentages [0.39622641509433965, 0.2339622641509434, 0.36981132075471695]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.51020443 0.73386157 0.64902544 0.53977275 0.8027762  0.5761814\n",
      "  0.8524705  0.72470784 0.8758353 ]]\n",
      "Counter({2: 126, 1: 91, 0: 62})\n",
      "batch percentages [0.2222222222222222, 0.32616487455197135, 0.45161290322580644]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.5290619  0.72054684 0.695313   0.6862117  0.7800478  0.66596913\n",
      "  0.75859976 0.63050795 0.70182145]]\n",
      "Counter({2: 156, 0: 85, 1: 32})\n",
      "batch percentages [0.31135531135531136, 0.11721611721611722, 0.5714285714285714]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.6726223  0.73235095 0.35938632 0.775537   0.7961774  0.5189419\n",
      "  0.68635    0.8071954  0.65231466]]\n",
      "Counter({2: 191, 0: 63, 1: 35})\n",
      "batch percentages [0.2179930795847751, 0.12110726643598616, 0.6608996539792388]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.77281106 0.44420934 0.6824206  0.80720246 0.8720318  0.76141024\n",
      "  0.808671   0.7342886  0.6637194 ]]\n",
      "Counter({0: 145, 2: 66, 1: 40})\n",
      "batch percentages [0.5776892430278885, 0.1593625498007968, 0.26294820717131473]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.7854537  0.6211951  0.68344617 0.79617846 0.8784026  0.7739682\n",
      "  0.6858417  0.7129288  0.53748345]]\n",
      "Counter({0: 166, 2: 60, 1: 19})\n",
      "batch percentages [0.6775510204081633, 0.07755102040816327, 0.24489795918367346]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.8186753  0.6355157  0.80240285 0.7644069  0.87006235 0.82305336\n",
      "  0.69586706 0.7377976  0.5877961 ]]\n",
      "Counter({0: 152, 1: 63, 2: 29})\n",
      "batch percentages [0.6229508196721312, 0.2581967213114754, 0.11885245901639344]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.5669761  0.2733724  0.83509016 0.33292294 0.5985304  0.83163023\n",
      "  0.27418756 0.3095392  0.5993552 ]]\n",
      "Counter({0: 146, 2: 51, 1: 48})\n",
      "batch percentages [0.5959183673469388, 0.19591836734693877, 0.20816326530612245]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43552494 0.48078167 0.8676733  0.37292063 0.64161766 0.8083992\n",
      "  0.49734282 0.51093507 0.62651753]]\n",
      "Counter({0: 120, 1: 92, 2: 31})\n",
      "batch percentages [0.49382716049382713, 0.3786008230452675, 0.12757201646090535]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.6722536  0.57784104 0.83618104 0.31701493 0.67795277 0.74568295\n",
      "  0.6848011  0.5494611  0.71889555]]\n",
      "Counter({0: 139, 1: 56, 2: 41})\n",
      "batch percentages [0.5889830508474576, 0.23728813559322035, 0.17372881355932204]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.75632596 0.5481318  0.85781384 0.36359918 0.7016345  0.6960529\n",
      "  0.75754416 0.3527565  0.80036473]]\n",
      "Counter({1: 112, 0: 91, 2: 45})\n",
      "batch percentages [0.36693548387096775, 0.45161290322580644, 0.1814516129032258]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.89993155 0.40440166 0.9049108  0.33745515 0.61579406 0.41047513\n",
      "  0.86067235 0.48146164 0.78034043]]\n",
      "Counter({1: 127, 0: 95, 2: 30})\n",
      "batch percentages [0.376984126984127, 0.503968253968254, 0.11904761904761904]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.608786   0.32315063 0.61943996 0.3120371  0.54439974 0.18457747\n",
      "  0.6860783  0.43031323 0.61135614]]\n",
      "Counter({1: 129, 0: 90, 2: 33})\n",
      "batch percentages [0.35714285714285715, 0.5119047619047619, 0.13095238095238096]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.65452087 0.48392427 0.7114985  0.38982904 0.59355044 0.16309333\n",
      "  0.8475039  0.5775304  0.65789676]]\n",
      "Counter({0: 138, 1: 101, 2: 4})\n",
      "batch percentages [0.5679012345679012, 0.4156378600823045, 0.01646090534979424]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.30144215 0.19083083 0.52202344 0.37444937 0.29708552 0.43418515\n",
      "  0.42622626 0.3474859  0.33237016]]\n",
      "Counter({0: 136, 1: 94, 2: 9})\n",
      "batch percentages [0.5690376569037657, 0.39330543933054396, 0.03765690376569038]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.47613764 0.3298211  0.4169234  0.3735783  0.4691571  0.3228109\n",
      "  0.56752765 0.5879377  0.34848332]]\n",
      "Counter({0: 160, 1: 60, 2: 16})\n",
      "batch percentages [0.6779661016949152, 0.2542372881355932, 0.06779661016949153]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40425146 0.2553414  0.42177677 0.2931769  0.44321346 0.29313755\n",
      "  0.44765925 0.48162687 0.38655198]]\n",
      "Counter({0: 160, 1: 52, 2: 24})\n",
      "batch percentages [0.6779661016949152, 0.22033898305084745, 0.1016949152542373]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.34531498 0.3537588  0.38423824 0.31516576 0.49398875 0.39912784\n",
      "  0.38764632 0.46721303 0.41992724]]\n",
      "Counter({0: 182, 1: 52, 2: 0})\n",
      "batch percentages [0.7777777777777778, 0.2222222222222222, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.3626312  0.2681793  0.4000064  0.38633978 0.47097516 0.29784167\n",
      "  0.4071691  0.3937956  0.36159074]]\n",
      "Counter({0: 181, 1: 51, 2: 1})\n",
      "batch percentages [0.776824034334764, 0.21888412017167383, 0.004291845493562232]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destroying NN_Player and Session...\n",
      "[[0.36745596 0.35330915 0.41312277 0.31147063 0.42753804 0.43105114\n",
      "  0.39097655 0.36911488 0.39982116]]\n",
      "Counter({0: 160, 1: 51, 2: 20})\n",
      "batch percentages [0.6926406926406926, 0.22077922077922077, 0.08658008658008658]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.49672902 0.48863387 0.5261749  0.31554246 0.5195421  0.4581324\n",
      "  0.3378563  0.3566513  0.41982222]]\n",
      "Counter({1: 131, 0: 114, 2: 0})\n",
      "batch percentages [0.46530612244897956, 0.5346938775510204, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4217869  0.4461708  0.51761687 0.34206176 0.5594008  0.47837067\n",
      "  0.39228833 0.43003857 0.5128069 ]]\n",
      "Counter({0: 165, 1: 68, 2: 4})\n",
      "batch percentages [0.6962025316455697, 0.2869198312236287, 0.016877637130801686]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.38340688 0.35524225 0.39408445 0.36578965 0.48618746 0.34261322\n",
      "  0.3682829  0.3990711  0.3813256 ]]\n",
      "Counter({0: 159, 1: 76, 2: 1})\n",
      "batch percentages [0.673728813559322, 0.3220338983050847, 0.00423728813559322]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42257416 0.39222527 0.39552188 0.28765666 0.4692254  0.31778586\n",
      "  0.40401804 0.31984997 0.40033484]]\n",
      "Counter({0: 167, 1: 66, 2: 5})\n",
      "batch percentages [0.7016806722689075, 0.2773109243697479, 0.02100840336134454]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.47349584 0.3737309  0.44333088 0.4105909  0.48505628 0.5153414\n",
      "  0.6481242  0.66789854 0.77583694]]\n",
      "Counter({0: 127, 1: 115, 2: 4})\n",
      "batch percentages [0.516260162601626, 0.46747967479674796, 0.016260162601626018]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.36663306 0.4630562  0.43581975 0.28538835 0.52817726 0.4035915\n",
      "  0.32955623 0.49868357 0.5368726 ]]\n",
      "Counter({0: 133, 1: 111, 2: 2})\n",
      "batch percentages [0.540650406504065, 0.45121951219512196, 0.008130081300813009]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.33017814 0.2861365  0.40926206 0.29866743 0.46998668 0.30114853\n",
      "  0.2776929  0.2588433  0.39323068]]\n",
      "Counter({0: 163, 1: 73, 2: 0})\n",
      "batch percentages [0.690677966101695, 0.3093220338983051, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43110585 0.36976588 0.45880985 0.3650111  0.47440827 0.39166057\n",
      "  0.3990711  0.3535018  0.45136666]]\n",
      "Counter({0: 174, 1: 60, 2: 2})\n",
      "batch percentages [0.7372881355932204, 0.2542372881355932, 0.00847457627118644]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.5276649  0.39261484 0.51422036 0.4246657  0.558552   0.4074725\n",
      "  0.46505666 0.4368894  0.48448133]]\n",
      "Counter({0: 168, 1: 67, 2: 0})\n",
      "batch percentages [0.7148936170212766, 0.2851063829787234, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.36522675 0.28909636 0.3721733  0.3068509  0.46846914 0.31210816\n",
      "  0.42137492 0.43034315 0.4299822 ]]\n",
      "Counter({0: 176, 1: 58, 2: 0})\n",
      "batch percentages [0.7521367521367521, 0.24786324786324787, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.3758005  0.341429   0.31659663 0.3069111  0.40631378 0.34793842\n",
      "  0.40011966 0.29004347 0.3943665 ]]\n",
      "Counter({0: 171, 1: 63, 2: 0})\n",
      "batch percentages [0.7307692307692307, 0.2692307692307692, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.46096563 0.4142046  0.4623382  0.3473313  0.44366634 0.37698102\n",
      "  0.44795918 0.3730198  0.45665622]]\n",
      "Counter({0: 133, 1: 113, 2: 0})\n",
      "batch percentages [0.540650406504065, 0.45934959349593496, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40076053 0.3287704  0.3983103  0.3119079  0.48288083 0.3610822\n",
      "  0.37061346 0.32799733 0.40533483]]\n",
      "Counter({0: 165, 1: 71, 2: 0})\n",
      "batch percentages [0.6991525423728814, 0.3008474576271186, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.33491898 0.3422016  0.38499022 0.3269868  0.42307305 0.3843515\n",
      "  0.4039086  0.3475734  0.3871739 ]]\n",
      "Counter({0: 175, 1: 61, 2: 0})\n",
      "batch percentages [0.7415254237288136, 0.2584745762711864, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.37195504 0.33107424 0.38790584 0.36904097 0.45473325 0.36273658\n",
      "  0.44101775 0.32533503 0.36176968]]\n",
      "Counter({0: 158, 1: 76, 2: 3})\n",
      "batch percentages [0.6666666666666666, 0.3206751054852321, 0.012658227848101266]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4054091  0.35943818 0.39778066 0.30573452 0.46379805 0.27925456\n",
      "  0.43885732 0.3253982  0.3866055 ]]\n",
      "Counter({0: 166, 1: 64, 2: 5})\n",
      "batch percentages [0.7063829787234043, 0.2723404255319149, 0.02127659574468085]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.437088   0.35150826 0.4013548  0.36862326 0.45301735 0.28475094\n",
      "  0.45975542 0.337664   0.44623816]]\n",
      "Counter({1: 136, 0: 111, 2: 1})\n",
      "batch percentages [0.4475806451612903, 0.5483870967741935, 0.004032258064516129]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4460522  0.3442794  0.38783228 0.39502668 0.48749948 0.3534813\n",
      "  0.42738593 0.33464015 0.44624805]]\n",
      "Counter({0: 149, 1: 82, 2: 4})\n",
      "batch percentages [0.6340425531914894, 0.34893617021276596, 0.01702127659574468]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4655478  0.39860892 0.4469242  0.4642322  0.5150871  0.5018867\n",
      "  0.64645636 0.8031112  0.5210581 ]]\n",
      "Counter({0: 149, 1: 48, 2: 43})\n",
      "batch percentages [0.6208333333333333, 0.2, 0.17916666666666667]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4245969  0.40588093 0.5012355  0.41394794 0.39170325 0.49147058\n",
      "  0.5141623  0.5258194  0.48831272]]\n",
      "Counter({0: 137, 1: 98, 2: 4})\n",
      "batch percentages [0.5732217573221757, 0.4100418410041841, 0.016736401673640166]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4424169  0.35745728 0.38431334 0.5133805  0.44650555 0.4562291\n",
      "  0.5124397  0.42989945 0.41310143]]\n",
      "Counter({0: 175, 1: 55, 2: 4})\n",
      "batch percentages [0.7478632478632479, 0.23504273504273504, 0.017094017094017096]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.48563898 0.431432   0.3549509  0.35226142 0.32925904 0.3525951\n",
      "  0.46427047 0.40432882 0.27733243]]\n",
      "Counter({0: 131, 1: 113, 2: 3})\n",
      "batch percentages [0.5303643724696356, 0.4574898785425101, 0.012145748987854251]\n",
      "duplicating session to freeze weights for evaluation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42673683 0.39900064 0.46940446 0.36937308 0.43322372 0.37036455\n",
      "  0.4773574  0.3757844  0.38205755]]\n",
      "Counter({1: 133, 0: 110, 2: 3})\n",
      "batch percentages [0.44715447154471544, 0.540650406504065, 0.012195121951219513]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4994464  0.3890351  0.3974172  0.64789724 0.5147668  0.32707584\n",
      "  0.5199075  0.43140388 0.46211064]]\n",
      "Counter({0: 171, 1: 64, 2: 0})\n",
      "batch percentages [0.7276595744680852, 0.2723404255319149, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.3488208  0.405303   0.38759327 0.43685675 0.43414712 0.37083066\n",
      "  0.37384307 0.30673242 0.4123224 ]]\n",
      "Counter({0: 168, 1: 65, 2: 2})\n",
      "batch percentages [0.7148936170212766, 0.2765957446808511, 0.00851063829787234]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4411     0.44646168 0.36764765 0.36859584 0.47957742 0.3633424\n",
      "  0.4631002  0.28520465 0.38316023]]\n",
      "Counter({0: 169, 1: 61, 2: 6})\n",
      "batch percentages [0.7161016949152542, 0.2584745762711864, 0.025423728813559324]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.41511786 0.40295422 0.36981905 0.36192775 0.43507433 0.3545357\n",
      "  0.40662467 0.34447384 0.40623546]]\n",
      "Counter({0: 169, 1: 62, 2: 2})\n",
      "batch percentages [0.7253218884120172, 0.26609442060085836, 0.008583690987124463]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42696178 0.3580774  0.4464841  0.36232388 0.43164062 0.3784566\n",
      "  0.41699302 0.37141657 0.4274546 ]]\n",
      "Counter({0: 147, 1: 95, 2: 0})\n",
      "batch percentages [0.6074380165289256, 0.3925619834710744, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.47749913 0.3952284  0.46186793 0.43485284 0.43769336 0.44768453\n",
      "  0.41514814 0.4367422  0.4471426 ]]\n",
      "Counter({0: 138, 1: 110, 2: 0})\n",
      "batch percentages [0.5564516129032258, 0.4435483870967742, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.45023906 0.35241544 0.39820778 0.40954435 0.48064482 0.36373913\n",
      "  0.33242524 0.3630997  0.3980391 ]]\n",
      "Counter({0: 167, 1: 69, 2: 0})\n",
      "batch percentages [0.7076271186440678, 0.2923728813559322, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.46598554 0.35952508 0.45690787 0.3728112  0.46898425 0.2960111\n",
      "  0.41624987 0.3611157  0.42089856]]\n",
      "Counter({0: 159, 1: 81, 2: 0})\n",
      "batch percentages [0.6625, 0.3375, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42637956 0.38007438 0.419608   0.37615943 0.42077315 0.32342803\n",
      "  0.41910577 0.38673544 0.4139675 ]]\n",
      "Counter({0: 136, 1: 109, 2: 3})\n",
      "batch percentages [0.5483870967741935, 0.43951612903225806, 0.012096774193548387]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.44681203 0.40320516 0.41206563 0.4069022  0.41855597 0.38936913\n",
      "  0.4534769  0.41591823 0.4495895 ]]\n",
      "Counter({1: 124, 0: 119, 2: 6})\n",
      "batch percentages [0.4779116465863454, 0.4979919678714859, 0.024096385542168676]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.41697228 0.47079813 0.3883072  0.6366662  0.520702   0.81680274\n",
      "  0.45899236 0.36295593 0.5322654 ]]\n",
      "Counter({0: 160, 1: 76, 2: 2})\n",
      "batch percentages [0.6722689075630253, 0.31932773109243695, 0.008403361344537815]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4861871  0.7681831  0.42009223 0.43184936 0.40339005 0.56849754\n",
      "  0.46350205 0.3332206  0.40568078]]\n",
      "Counter({0: 155, 1: 85, 2: 1})\n",
      "batch percentages [0.6431535269709544, 0.35269709543568467, 0.004149377593360996]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42322636 0.5664208  0.4406489  0.34997666 0.45908487 0.53225493\n",
      "  0.415722   0.28809416 0.40935814]]\n",
      "Counter({0: 169, 1: 65, 2: 0})\n",
      "batch percentages [0.7222222222222222, 0.2777777777777778, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.405617   0.5220524  0.3869747  0.34196293 0.4884411  0.47111905\n",
      "  0.42788064 0.3465823  0.47329104]]\n",
      "Counter({0: 166, 1: 68, 2: 2})\n",
      "batch percentages [0.7033898305084746, 0.288135593220339, 0.00847457627118644]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4103042  0.41430664 0.46372962 0.3584286  0.9283806  0.36220467\n",
      "  0.51866055 0.26242983 0.38643217]]\n",
      "Counter({0: 174, 1: 61, 2: 0})\n",
      "batch percentages [0.7404255319148936, 0.25957446808510637, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.39553094 0.3429525  0.4461689  0.42335784 0.6086129  0.44852376\n",
      "  0.4825003  0.36152697 0.45139503]]\n",
      "Counter({0: 173, 1: 61, 2: 0})\n",
      "batch percentages [0.7393162393162394, 0.2606837606837607, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40549886 0.37814915 0.3964995  0.34922886 0.59849465 0.4285072\n",
      "  0.45775867 0.40366745 0.40995622]]\n",
      "Counter({0: 179, 1: 53, 2: 1})\n",
      "batch percentages [0.7682403433476395, 0.22746781115879827, 0.004291845493562232]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.35879004 0.31709468 0.4274614  0.34333408 0.5252148  0.38784623\n",
      "  0.44841063 0.4175055  0.3977201 ]]\n",
      "Counter({0: 179, 1: 58, 2: 0})\n",
      "batch percentages [0.7552742616033755, 0.24472573839662448, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.35912502 0.33471656 0.3752817  0.372998   0.5194129  0.4388064\n",
      "  0.39111674 0.36472762 0.4285395 ]]\n",
      "Counter({0: 158, 1: 80, 2: 0})\n",
      "batch percentages [0.6638655462184874, 0.33613445378151263, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.48378026 0.38306773 0.37290335 0.3898548  0.44024563 0.37378037\n",
      "  0.39977145 0.34874618 0.40981233]]\n",
      "Counter({1: 129, 0: 119, 2: 0})\n",
      "batch percentages [0.4798387096774194, 0.5201612903225806, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4657923  0.40976143 0.44989026 0.45674145 0.46093237 0.41947222\n",
      "  0.44927    0.3596624  0.4334557 ]]\n",
      "Counter({0: 129, 1: 118, 2: 0})\n",
      "batch percentages [0.5222672064777328, 0.4777327935222672, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43813324 0.36102176 0.4269557  0.39212215 0.403749   0.35943866\n",
      "  0.38719833 0.3019235  0.35181725]]\n",
      "Counter({0: 133, 1: 108, 2: 0})\n",
      "batch percentages [0.5518672199170125, 0.44813278008298757, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.434245   0.35993063 0.40026975 0.34267282 0.4485587  0.36563122\n",
      "  0.4234209  0.39132297 0.4812112 ]]\n",
      "Counter({0: 123, 1: 121, 2: 3})\n",
      "batch percentages [0.4979757085020243, 0.4898785425101215, 0.012145748987854251]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4159931  0.37224007 0.44296825 0.31737828 0.46321404 0.3291011\n",
      "  0.41769946 0.39057124 0.4751655 ]]\n",
      "Counter({0: 139, 1: 107, 2: 0})\n",
      "batch percentages [0.5650406504065041, 0.4349593495934959, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.38655496 0.33508825 0.40542603 0.38664198 0.47362816 0.37584043\n",
      "  0.3952676  0.40814602 0.45322847]]\n",
      "Counter({0: 160, 1: 76, 2: 0})\n",
      "batch percentages [0.6779661016949152, 0.3220338983050847, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.45566893 0.33846414 0.37970054 0.33122814 0.47030878 0.31096852\n",
      "  0.3466289  0.36213362 0.38829863]]\n",
      "Counter({0: 162, 1: 76, 2: 0})\n",
      "batch percentages [0.680672268907563, 0.31932773109243695, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4074055  0.3814603  0.4320748  0.35322547 0.52251256 0.3341688\n",
      "  0.40790832 0.40764832 0.3283    ]]\n",
      "Counter({0: 177, 1: 56, 2: 3})\n",
      "batch percentages [0.75, 0.23728813559322035, 0.012711864406779662]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4758798  0.34577525 0.43472767 0.356362   0.45777154 0.3794074\n",
      "  0.481717   0.42452753 0.45416546]]\n",
      "Counter({0: 143, 1: 103, 2: 0})\n",
      "batch percentages [0.5813008130081301, 0.4186991869918699, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.45402277 0.3940537  0.4514147  0.3535111  0.44603407 0.36475897\n",
      "  0.4572419  0.3799504  0.40209436]]\n",
      "Counter({0: 128, 1: 119, 2: 0})\n",
      "batch percentages [0.5182186234817814, 0.4817813765182186, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.48841512 0.4652766  0.42549372 0.35810757 0.7750708  0.4793849\n",
      "  0.39859676 0.38863146 0.46054482]]\n",
      "Counter({0: 154, 1: 73, 2: 9})\n",
      "batch percentages [0.652542372881356, 0.3093220338983051, 0.038135593220338986]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4395659  0.3461411  0.45441163 0.3971578  0.5470023  0.40928388\n",
      "  0.45322084 0.4204682  0.4149133 ]]\n",
      "Counter({0: 167, 1: 68, 2: 0})\n",
      "batch percentages [0.7106382978723405, 0.28936170212765955, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.38784087 0.41033316 0.46507013 0.36772823 0.5158448  0.38542914\n",
      "  0.36310172 0.34821284 0.39607704]]\n",
      "Counter({0: 176, 1: 58, 2: 0})\n",
      "batch percentages [0.7521367521367521, 0.24786324786324787, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.35743916 0.37494528 0.39431274 0.38817894 0.49222386 0.38596416\n",
      "  0.41465318 0.31527007 0.3978268 ]]\n",
      "Counter({0: 157, 1: 76, 2: 4})\n",
      "batch percentages [0.6624472573839663, 0.3206751054852321, 0.016877637130801686]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.49559784 0.47359228 0.44430685 0.37576187 0.50308454 0.4283495\n",
      "  0.42812192 0.39760292 0.49063647]]\n",
      "Counter({0: 171, 1: 64, 2: 0})\n",
      "batch percentages [0.7276595744680852, 0.2723404255319149, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4592607  0.3834436  0.48845792 0.41356385 0.4683658  0.44844043\n",
      "  0.47837472 0.39107275 0.480932  ]]\n",
      "Counter({0: 140, 1: 106, 2: 2})\n",
      "batch percentages [0.5645161290322581, 0.4274193548387097, 0.008064516129032258]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43077624 0.32410026 0.484164   0.35399628 0.44640017 0.3751335\n",
      "  0.45774603 0.3733549  0.4055239 ]]\n",
      "Counter({0: 123, 1: 123, 2: 0})\n",
      "batch percentages [0.5, 0.5, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40415025 0.3750198  0.4048041  0.3695556  0.44213068 0.350137\n",
      "  0.41972017 0.34965885 0.40771914]]\n",
      "Counter({0: 170, 1: 62, 2: 0})\n",
      "batch percentages [0.7327586206896551, 0.2672413793103448, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4241575  0.3633567  0.43572485 0.36344755 0.46620512 0.4296744\n",
      "  0.43804574 0.42352867 0.37586248]]\n",
      "Counter({0: 157, 1: 77, 2: 0})\n",
      "batch percentages [0.6709401709401709, 0.32905982905982906, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.46654737 0.3717817  0.42072976 0.35871518 0.51190734 0.38178337\n",
      "  0.39971828 0.39385462 0.41657746]]\n",
      "Counter({0: 167, 1: 68, 2: 0})\n",
      "batch percentages [0.7106382978723405, 0.28936170212765955, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.420092   0.3291564  0.4351437  0.36982238 0.4663881  0.40078962\n",
      "  0.44439948 0.38244486 0.4215337 ]]\n",
      "Counter({0: 174, 1: 61, 2: 0})\n",
      "batch percentages [0.7404255319148936, 0.25957446808510637, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4356649  0.3835175  0.44193172 0.40341592 0.41800535 0.40959203\n",
      "  0.43549848 0.33731735 0.40037048]]\n",
      "Counter({0: 135, 1: 110, 2: 2})\n",
      "batch percentages [0.5465587044534413, 0.44534412955465585, 0.008097165991902834]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.31455433 0.33738685 0.35692823 0.3373251  0.41173315 0.33134294\n",
      "  0.33945024 0.3572321  0.3507049 ]]\n",
      "Counter({0: 179, 1: 56, 2: 0})\n",
      "batch percentages [0.7617021276595745, 0.23829787234042554, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40391743 0.43197763 0.4604026  0.3593222  0.47745812 0.3741498\n",
      "  0.4263636  0.35366833 0.45171547]]\n",
      "Counter({0: 168, 1: 68, 2: 3})\n",
      "batch percentages [0.702928870292887, 0.28451882845188287, 0.012552301255230125]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.39699244 0.3545612  0.38390017 0.35439873 0.4384327  0.3450861\n",
      "  0.3529942  0.3753115  0.37952805]]\n",
      "Counter({0: 159, 1: 76, 2: 0})\n",
      "batch percentages [0.676595744680851, 0.32340425531914896, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42022598 0.3622986  0.4458182  0.40159166 0.5127057  0.38838148\n",
      "  0.43857265 0.42556703 0.4637462 ]]\n",
      "Counter({0: 175, 1: 57, 2: 0})\n",
      "batch percentages [0.7543103448275862, 0.24568965517241378, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.39196694 0.34537005 0.3906101  0.31300366 0.4432298  0.3094511\n",
      "  0.42201805 0.29974616 0.39738727]]\n",
      "Counter({0: 167, 1: 62, 2: 4})\n",
      "batch percentages [0.7167381974248928, 0.26609442060085836, 0.017167381974248927]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4099077  0.40400672 0.41002285 0.32138968 0.46690142 0.3794737\n",
      "  0.44581378 0.41019917 0.42562997]]\n",
      "Counter({0: 160, 1: 76, 2: 1})\n",
      "batch percentages [0.6751054852320675, 0.3206751054852321, 0.004219409282700422]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.48479772 0.3639711  0.45921898 0.32483912 0.4629842  0.44360125\n",
      "  0.47184622 0.40989852 0.46793008]]\n",
      "Counter({0: 128, 1: 120, 2: 0})\n",
      "batch percentages [0.5161290322580645, 0.4838709677419355, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.47376108 0.32889867 0.50607777 0.33541274 0.46806931 0.4147817\n",
      "  0.43529832 0.37451196 0.41326165]]\n",
      "Counter({0: 141, 1: 106, 2: 0})\n",
      "batch percentages [0.5708502024291497, 0.4291497975708502, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4066831  0.34116364 0.40315473 0.3360002  0.4109962  0.35973382\n",
      "  0.43557096 0.29316962 0.37726128]]\n",
      "Counter({0: 135, 1: 111, 2: 0})\n",
      "batch percentages [0.5487804878048781, 0.45121951219512196, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.44414794 0.33926666 0.39663756 0.36309898 0.409392   0.30143917\n",
      "  0.43816864 0.328745   0.36464727]]\n",
      "Counter({1: 127, 0: 119, 2: 0})\n",
      "batch percentages [0.483739837398374, 0.516260162601626, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43677235 0.34821355 0.45488477 0.3261181  0.46047866 0.35097885\n",
      "  0.474064   0.3692609  0.42075205]]\n",
      "Counter({0: 138, 1: 109, 2: 0})\n",
      "batch percentages [0.5587044534412956, 0.44129554655870445, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40833116 0.6237117  0.44227684 0.3744601  0.83520377 0.46683943\n",
      "  0.40834963 0.32545578 0.4259392 ]]\n",
      "Counter({0: 169, 1: 67, 2: 0})\n",
      "batch percentages [0.7161016949152542, 0.2838983050847458, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.38511825 0.35616505 0.42175937 0.35015845 0.45379615 0.38621068\n",
      "  0.37800455 0.32453823 0.3902861 ]]\n",
      "Counter({0: 168, 1: 68, 2: 0})\n",
      "batch percentages [0.711864406779661, 0.288135593220339, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42730832 0.4187256  0.45124173 0.34932137 0.49752712 0.43172336\n",
      "  0.4009832  0.37377322 0.43886042]]\n",
      "Counter({0: 176, 1: 58, 2: 1})\n",
      "batch percentages [0.7489361702127659, 0.24680851063829787, 0.00425531914893617]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.39634383 0.31333947 0.4095161  0.41907048 0.4323926  0.3415872\n",
      "  0.33761954 0.36880827 0.38358247]]\n",
      "Counter({0: 176, 1: 60, 2: 0})\n",
      "batch percentages [0.7457627118644068, 0.2542372881355932, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.44442892 0.40824306 0.45060265 0.46903908 0.48029578 0.43131566\n",
      "  0.4209051  0.38582432 0.45321858]]\n",
      "Counter({0: 165, 1: 71, 2: 0})\n",
      "batch percentages [0.6991525423728814, 0.3008474576271186, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4218719  0.4234755  0.3816787  0.3784809  0.4747975  0.40532327\n",
      "  0.4448892  0.3515675  0.4786266 ]]\n",
      "Counter({0: 132, 1: 113, 2: 1})\n",
      "batch percentages [0.5365853658536586, 0.45934959349593496, 0.0040650406504065045]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.496171   0.39536035 0.4757352  0.37712073 0.67802846 0.6101786\n",
      "  0.43068182 0.41971612 0.48504817]]\n",
      "Counter({0: 170, 1: 69, 2: 0})\n",
      "batch percentages [0.7112970711297071, 0.28870292887029286, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.39751852 0.40135407 0.3969344  0.35990477 0.5938591  0.44152212\n",
      "  0.4103217  0.3283366  0.40207016]]\n",
      "Counter({0: 156, 1: 80, 2: 1})\n",
      "batch percentages [0.6582278481012658, 0.33755274261603374, 0.004219409282700422]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4020183  0.38266993 0.37298536 0.32830918 0.48984075 0.32561815\n",
      "  0.46273363 0.43089902 0.43696284]]\n",
      "Counter({0: 163, 1: 74, 2: 0})\n",
      "batch percentages [0.6877637130801688, 0.31223628691983124, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.41217744 0.36829007 0.40264833 0.37740254 0.43161368 0.3679334\n",
      "  0.42945182 0.38876116 0.4346187 ]]\n",
      "Counter({1: 124, 0: 122, 2: 0})\n",
      "batch percentages [0.4959349593495935, 0.5040650406504065, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.41682625 0.44130695 0.43040955 0.34558582 0.51189935 0.319538\n",
      "  0.43618786 0.41172063 0.432891  ]]\n",
      "Counter({0: 170, 1: 64, 2: 0})\n",
      "batch percentages [0.7264957264957265, 0.27350427350427353, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4246248  0.38076568 0.43849587 0.38162315 0.46826804 0.31539702\n",
      "  0.45713806 0.41268897 0.47802508]]\n",
      "Counter({0: 125, 1: 120, 2: 2})\n",
      "batch percentages [0.5060728744939271, 0.48582995951417, 0.008097165991902834]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4248494  0.3975829  0.35863614 0.3816887  0.4831184  0.41174567\n",
      "  0.4068017  0.39995253 0.5192661 ]]\n",
      "Counter({0: 130, 1: 116, 2: 2})\n",
      "batch percentages [0.5241935483870968, 0.46774193548387094, 0.008064516129032258]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.35722077 0.36658478 0.39679396 0.37748027 0.4423262  0.30888963\n",
      "  0.41203594 0.38066542 0.37891078]]\n",
      "Counter({0: 165, 1: 66, 2: 8})\n",
      "batch percentages [0.6903765690376569, 0.27615062761506276, 0.03347280334728033]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.40603518 0.3077017  0.44542444 0.39405203 0.45204043 0.3146639\n",
      "  0.42103612 0.38201702 0.40214956]]\n",
      "Counter({0: 166, 1: 70, 2: 0})\n",
      "batch percentages [0.7033898305084746, 0.2966101694915254, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.45288873 0.4046769  0.45659566 0.39292645 0.490389   0.365139\n",
      "  0.4599359  0.42209542 0.43983126]]\n",
      "Counter({0: 154, 1: 83, 2: 0})\n",
      "batch percentages [0.6497890295358649, 0.350210970464135, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.41001642 0.40561342 0.43402755 0.39620876 0.48044407 0.40474117\n",
      "  0.45825005 0.39395738 0.39750528]]\n",
      "Counter({0: 159, 1: 75, 2: 2})\n",
      "batch percentages [0.673728813559322, 0.3177966101694915, 0.00847457627118644]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.428038   0.37512362 0.4413458  0.37930298 0.5001781  0.39134037\n",
      "  0.4505651  0.420133   0.38628447]]\n",
      "Counter({0: 173, 1: 61, 2: 0})\n",
      "batch percentages [0.7393162393162394, 0.2606837606837607, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42784035 0.3862059  0.45850456 0.4030651  0.46476638 0.43729687\n",
      "  0.45949316 0.34751332 0.415424  ]]\n",
      "Counter({0: 162, 1: 73, 2: 2})\n",
      "batch percentages [0.6835443037974683, 0.3080168776371308, 0.008438818565400843]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.36662614 0.3667016  0.40099204 0.3302058  0.46275496 0.36788917\n",
      "  0.36666775 0.29979038 0.37205648]]\n",
      "Counter({0: 172, 1: 61, 2: 0})\n",
      "batch percentages [0.7381974248927039, 0.26180257510729615, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.37723255 0.2880888  0.41668487 0.31267667 0.39344454 0.37250328\n",
      "  0.3717171  0.32772887 0.4080124 ]]\n",
      "Counter({0: 124, 1: 122, 2: 0})\n",
      "batch percentages [0.5040650406504065, 0.4959349593495935, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42633915 0.32622695 0.43644464 0.38646448 0.45660567 0.39753914\n",
      "  0.4061538  0.3750142  0.41689932]]\n",
      "Counter({0: 165, 1: 72, 2: 0})\n",
      "batch percentages [0.6962025316455697, 0.3037974683544304, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42285192 0.36565435 0.43818796 0.35298753 0.48950875 0.38881028\n",
      "  0.43182516 0.45497394 0.39475095]]\n",
      "Counter({0: 156, 1: 76, 2: 1})\n",
      "batch percentages [0.6695278969957081, 0.3261802575107296, 0.004291845493562232]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.37364423 0.3676077  0.41628122 0.34371197 0.4302839  0.3490907\n",
      "  0.3966446  0.3198359  0.39623582]]\n",
      "Counter({0: 180, 1: 53, 2: 0})\n",
      "batch percentages [0.7725321888412017, 0.22746781115879827, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.43812644 0.39701688 0.43939614 0.32414138 0.4230218  0.3651123\n",
      "  0.40043604 0.34809005 0.42797506]]\n",
      "Counter({1: 127, 0: 119, 2: 0})\n",
      "batch percentages [0.483739837398374, 0.516260162601626, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.42389905 0.4091512  0.46335173 0.35598898 0.47964275 0.35568047\n",
      "  0.46806288 0.3821386  0.4142878 ]]\n",
      "Counter({0: 160, 1: 73, 2: 0})\n",
      "batch percentages [0.6866952789699571, 0.3133047210300429, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.45724785 0.3568189  0.4183482  0.3495667  0.43811464 0.3371718\n",
      "  0.43821406 0.4129933  0.3826114 ]]\n",
      "Counter({1: 130, 0: 117, 2: 0})\n",
      "batch percentages [0.47368421052631576, 0.5263157894736842, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.37915134 0.36308813 0.42890418 0.33387625 0.47192132 0.27802372\n",
      "  0.36789858 0.39377785 0.43493223]]\n",
      "Counter({0: 150, 1: 88, 2: 0})\n",
      "batch percentages [0.6302521008403361, 0.3697478991596639, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n",
      "[[0.4047234  0.36067092 0.41256082 0.35584962 0.4737724  0.40530992\n",
      "  0.3672806  0.3275807  0.39437568]]\n",
      "Counter({0: 170, 1: 62, 2: 0})\n",
      "batch percentages [0.7327586206896551, 0.2672413793103448, 0.0]\n",
      "duplicating session to freeze weights for evaluation...\n",
      "INFO:tensorflow:Restoring parameters from ./to_duplicate.ckpt\n",
      "Destroying NN_Player and Session...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-7f517c207768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m#Collect rollouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_time_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m#Add rollouts to the replay buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-42e567fc4ced>\u001b[0m in \u001b[0;36mbatch_rollout\u001b[0;34m(player, opponent, env, max_time_steps)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mtime_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mtime_steps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_time_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_trajectory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mopponent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mpaths\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbatch_winners\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_winner\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-42e567fc4ced>\u001b[0m in \u001b[0;36msample_trajectory\u001b[0;34m(player, opponent, env)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopponent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mob\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlegal_moves\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;31m#Need to record final reward for player 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/ai/TicTacToe/venv/TicTacToe.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;31m#test for full board\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_winner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m     return _methods._amin(a, axis=axis,\n\u001b[0;32m-> 2420\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "reload(Players)\n",
    "\n",
    "#Define the placeholders\n",
    "observation_placeholder = tf.placeholder(shape = [None, 3,3], dtype = tf.int32, name = \"obs_placeholder\")\n",
    "action_placeholder = tf.placeholder(shape = [None], dtype = tf.int32, name = \"act_placeholder\")\n",
    "\n",
    "#target place holder is r(s,a) + \\gamma \\max_a Q(s',a)\n",
    "target_placeholder = tf.placeholder(shape = [None], dtype = tf.float32, name = \"target_placeholder\")\n",
    "\n",
    "#Define the model and loss function\n",
    "model = TicTacToe_model(observation_placeholder, scope = \"Q_learn\")\n",
    "update_op = symbolic_Q_update(model, target_placeholder, action_placeholder)\n",
    "\n",
    "#Start a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Define the players\n",
    "player = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = False)\n",
    "opponent = Players.Random_Player()\n",
    "\n",
    "\n",
    "#Define the environment\n",
    "env = TicTacToe.TicTacToe()\n",
    "\n",
    "#Load current net\n",
    "temp_file_name = './bot_10_31_q_v2.ckpt'\n",
    "\n",
    "#Want to duplicate session\n",
    "#saver = tf.train.Saver()\n",
    "#saver.restore(sess, temp_file_name)\n",
    "\n",
    "replay_buffer = []\n",
    "first_state = None\n",
    "step = 0\n",
    "while True:\n",
    "    step += 1\n",
    "    \n",
    "    #Collect rollouts\n",
    "    paths, _ = batch_rollout(player, opponent, env, max_time_steps = 100)\n",
    "    \n",
    "    #Add rollouts to the replay buffer\n",
    "    if len(replay_buffer) > 100000:\n",
    "        replay_buffer = paths\n",
    "    else:\n",
    "        replay_buffer += paths\n",
    "    \n",
    "    #Collect samples from our replay buffer\n",
    "    states, actions, next_states, rewards, masks, not_end_of_path = sample_paths(replay_buffer, batch_size = 100)\n",
    "    \n",
    "    #Compute target values\n",
    "    target_values = compute_target_values(model, next_states, masks, not_end_of_path, rewards, verbose=False)\n",
    "    \n",
    "    #Update the network\n",
    "    sess.run(update_op, feed_dict= {observation_placeholder : states, action_placeholder : actions, target_placeholder : target_values })\n",
    "    \n",
    "    \n",
    "    #Occasionally, test the model and replace it with a previous iteration\n",
    "    if step%1000 ==0:\n",
    "        step = 0\n",
    "#        print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,0,0],[0,0,0]])] }))\n",
    "        player.epsilon = 0\n",
    "        expert_player = Players.Child_Player()\n",
    "        _, expert_batch_winners = batch_rollout(player, expert_player, env, max_time_steps=1000)\n",
    "        print(expert_batch_winners)\n",
    "        batch_percentages = np.array([expert_batch_winners[0], expert_batch_winners[1], expert_batch_winners[2]])*1.0/(expert_batch_winners[0] + expert_batch_winners[1] + expert_batch_winners[2])\n",
    "        player.epsilon = .2\n",
    "        print(\"batch percentages\", batch_percentages.tolist())\n",
    "        opponent = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = True)\n",
    "        \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training against expert policy, to see if this works at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,0,0],[0,0,0]])] }))\n",
    "print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,1,0],[0,0,-1]])] }))\n",
    "print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,-1,-1],[0,0,1]])] }))\n",
    "player.epsilon = 0\n",
    "expert_player = Players.Random_Player()\n",
    "_, expert_batch_winners = batch_rollout(player, expert_player, env, max_time_steps=1000)\n",
    "print(expert_batch_winners)\n",
    "batch_percentages = np.array([expert_batch_winners[0], expert_batch_winners[1], expert_batch_winners[2]])*1.0/(expert_batch_winners[0] + expert_batch_winners[1] + expert_batch_winners[2])\n",
    "player.epsilon = .2\n",
    "print(\"batch percentages\", batch_percentages.tolist())\n",
    "opponent = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code that Nick might want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-34-15257dded3e9>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-34-15257dded3e9>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    states, actions, next_states, rewards, masks, not_end_of_path = sample_paths(replay_buffer, batch_size = 100)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "###Taken from the bottom of Q-learning training, after 'replay_buffer'\n",
    "\n",
    "    states, actions, next_states, rewards, masks, not_end_of_path = sample_paths(replay_buffer, batch_size = 100)\n",
    "    target_values = compute_target_values(model, next_states, masks, not_end_of_path, rewards, verbose=False)\n",
    "#     for state, neof, act, target in zip(states, not_end_of_path, actions,target_values):\n",
    "#         if first_state is None:\n",
    "#             if neof == 0:\n",
    "#                 first_state = state\n",
    "#         elif np.max(np.abs(first_state-state))==0:\n",
    "#             print(state)\n",
    "#             print(\"current q values\", sess.run(model,feed_dict= {observation_placeholder : [state]}))\n",
    "#             print(\"current action\", act)\n",
    "#             print(\"current target\", target)\n",
    "            \n",
    "            \n",
    "#     print(target_values[0])\n",
    "#    for i, shit in enumerate(zip(target_values, states, actions, next_states, rewards, masks, not_end_of_path)):\n",
    "#       print(i, shit)\n",
    "#    rewards_for_average =np.concatenate([rewards_for_average,rewards])\n",
    "#    test_obs = np.array([[[ 1, 2,  2],[ 0, 2,  2],[ 0,  1,  1]]])\n",
    "#    test_act = np.array([2])\n",
    "#    test_targ = np.array([-1.0])\n",
    "#    sess.run(update_op, feed_dict= {observation_placeholder : test_obs, action_placeholder : test_act, target_placeholder : test_targ })\n",
    "#    print(sess.run(model, feed_dict= {observation_placeholder : test_obs}) )\n",
    "#    vals = sess.run(model, feed_dict = {observation_placeholder: states})\n",
    "#    old = []\n",
    "    sess.run(update_op, feed_dict= {observation_placeholder : states, action_placeholder : actions, target_placeholder : target_values })\n",
    "    \n",
    "    if step%1000 ==0:\n",
    "        step = 0\n",
    "        print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,0,0],[0,0,0]])] }))\n",
    "        print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,1,0],[0,0,-1]])] }))\n",
    "        print(sess.run(model, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,-1,-1],[0,0,1]])] }))\n",
    "        player.epsilon = 0\n",
    "        expert_player = Players.Random_Player()\n",
    "        _, expert_batch_winners = batch_rollout(player, expert_player, env, max_time_steps=1000)\n",
    "        print(expert_batch_winners)\n",
    "        batch_percentages = np.array([expert_batch_winners[0], expert_batch_winners[1], expert_batch_winners[2]])*1.0/(expert_batch_winners[0] + expert_batch_winners[1] + expert_batch_winners[2])\n",
    "        player.epsilon = .2\n",
    "        print(\"batch percentages\", batch_percentages.tolist())\n",
    "        opponent = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = True)\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shapes (?,) and (?, 3, 9) are incompatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9e2dc40f24a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Q_learn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTicTacToe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"target_network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msymbolic_Q_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#Start a session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-426f195e4735>\u001b[0m in \u001b[0;36msymbolic_Q_update\u001b[0;34m(model, target_placeholder, action_placeholder, learning_rate)\u001b[0m\n\u001b[1;32m     17\u001b[0m     '''\n\u001b[1;32m     18\u001b[0m     \u001b[0mq_action_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_action_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(labels, predictions, weights, scope, loss_collection, reduction)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_is_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquared_difference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     return compute_weighted_loss(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \"\"\"\n\u001b[1;32m    846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are incompatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mmost_specific_compatible_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (?,) and (?, 3, 9) are incompatible"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "reload(Players)\n",
    "\n",
    "#Define the placeholders\n",
    "observation_placeholder = tf.placeholder(shape = [None, 3,3], dtype = tf.int32, name = \"obs_placeholder\")\n",
    "action_placeholder = tf.placeholder(shape = [None], dtype = tf.int32, name = \"act_placeholder\")\n",
    "\n",
    "#target place holder is r(s,a) + \\gamma \\max_a Q(s',a)\n",
    "target_placeholder = tf.placeholder(shape = [None], dtype = tf.float32, name = \"target_placeholder\")\n",
    "\n",
    "#Define the model and loss function\n",
    "model = TicTacToe_model(observation_placeholder, scope = \"Q_learn\")\n",
    "target_model = TicTacToe_model(observation_placeholder, scope = \"target_network\")\n",
    "update_op = symbolic_Q_update(model, target_placeholder, action_placeholder)\n",
    "\n",
    "#Start a session\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#Define the players\n",
    "player = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = False)\n",
    "opponent = Players.Random_Player()\n",
    "judge =  Players.NN_Player(target_model, target_model, sess, observation_placeholder, duplicate = False)\n",
    "\n",
    "\n",
    "#Define the environment\n",
    "env = TicTacToe.TicTacToe()\n",
    "\n",
    "#Load current net\n",
    "temp_file_name = './bot_10_31_q_v2.ckpt'\n",
    "\n",
    "#Want to duplicate session\n",
    "#saver = tf.train.Saver()\n",
    "#saver.restore(sess, temp_file_name)\n",
    "\n",
    "replay_buffer = []\n",
    "first_state = None\n",
    "step = 0\n",
    "\n",
    "while True:\n",
    "    step += 1\n",
    "\n",
    "    #Collect rollouts\n",
    "    paths, _ = batch_rollout(player, opponent, env, max_time_steps = 100)\n",
    "\n",
    "    #Add rollouts to the replay buffer\n",
    "    if len(replay_buffer) > 100000:\n",
    "        replay_buffer = paths\n",
    "    else:\n",
    "        replay_buffer += paths\n",
    "\n",
    "    #Collect samples from our replay buffer\n",
    "    states, actions, next_states, rewards, masks, not_end_of_path = sample_paths(replay_buffer, batch_size = 100)\n",
    "\n",
    "    #Compute target values\n",
    "    target_values = compute_target_values(target_model, next_states, masks, not_end_of_path, rewards, verbose=False)\n",
    "    print(target_values)\n",
    "    #Update the network\n",
    "    sess.run(update_op, feed_dict= {observation_placeholder : states, action_placeholder : actions, target_placeholder : target_values })\n",
    "\n",
    "    if steps % 200 ==0:\n",
    "        judge = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = True)\n",
    "        #target_model updates to current model\n",
    "        print(\"target has updated\")\n",
    "\n",
    "\n",
    "    #Occasionally, test the model and replace it with a previous iteration\n",
    "    if step%1000 ==0:\n",
    "        step = 0\n",
    "        print(sess.run(judge, feed_dict= {observation_placeholder : [np.array([[0,0,0],[0,0,0],[0,0,0]])] }))\n",
    "        player.epsilon = 0\n",
    "        expert_player = Players.Child_Player()\n",
    "        _, expert_batch_winners = batch_rollout(player, expert_player, env, max_time_steps=1000)\n",
    "        print(expert_batch_winners)\n",
    "        batch_percentages = np.array([expert_batch_winners[0], expert_batch_winners[1], expert_batch_winners[2]])*1.0/(expert_batch_winners[0] + expert_batch_winners[1] + expert_batch_winners[2])\n",
    "        player.epsilon = .2\n",
    "        print(\"batch percentages\", batch_percentages.tolist())\n",
    "        opponent = Players.NN_Player(model, model, sess, observation_placeholder, duplicate = True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
